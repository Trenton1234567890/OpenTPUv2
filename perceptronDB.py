import numpy as np

LEARNING_RATE = 0.1
MAX_ITERATION = 1
coreMMR_base_addr = 0x4000B000

def calculate_output(weights, x, y):
    sum_value = x * weights[0] + y * weights[1] + weights[2]
    return 1 if sum_value >= 0 else -1

def main():
    weights = np.array([1.302589, 1.1, 0.023030], dtype=np.float32)
    local_error, global_error = 0, 0
    pattern_count = 208
    iteration = 0
    output = 0

    x = np.array([1.456044, -4.478022, -7.664835, -5.137363, -8.818681, 3.653846, -5.686813, -5.961538, 5.961538, -6.620879, -8.159341, 5.027473, 2.994505, -3.818681, 5.192308, -8.653846, 4.148352, 0.521978, -4.807692, -3.818681, -7.115385, -8.763736, 5.192308, 3.598901, -5.576923, -8.489011, 1.456044, 0.796703, -2.994505, -2.28022, -3.708791, -5.247253, -0.851648, -3.269231, -7.005495, -5.192308, -1.840659, -4.807692, -3.543956, 4.917582, 1.401099, 1.785714, -1.895604, 7.39011, -1.565934, 1.016484, -4.587912, -2.93956, -4.203297, 3.269231, -3.049451, 4.587912, -2.445055, 3.818681, -2.06044, 6.565934, 2.335165, -3.818681, 5.412088, 4.862637, -9.038462, -9.313187, -0.247253, 7.82967, -8.928571, 7.71978, 4.752747, -4.917582, -0.851648, -9.258242, -7.994505, -7.774725, 6.346154, 6.675824, -5.082418, 4.203297, 1.071429, -8.214286, -9.203297, 1.620879, 1.895604, 0.631868, 5.027473, -3.708791, -1.620879, 7.17033, -8.598901, 7.82967, -1.236264, -7.39011, 3.928571, -2.06044, 4.368132, -0.686813, 5.686813, 4.862637, -2.884615, -1.456044, -7.60989, -1.456044, -0.686813, -0.302198, 4.093407, -3.653846, -0.247253, -1.346154, 7.71978, -2.884615, 3.324176, 7.445055, 0.686813, 6.675824, 1.126374, 4.478022, -0.906593, 4.258242, 6.510989, 6.510989, 5.412088, -8.104396, -8.983516, 1.620879, 4.862637, 6.016484, -5.741758, -6.236264, -7.60989, -1.016484, -4.862637, 2.994505, 6.950549, -6.950549, 2.5, -6.401099, -2.28022, -2.60989, -4.313187, -0.741758, 3.379121, -3.379121, -5.961538, 1.510989, 0.247253, -7.664835, 2.554945, -6.126374, -4.368132, -0.027473, 1.840659, 3.049451, 2.005495, 6.950549, 6.181319, -5.082418, 1.346154, 5.631868, 3.159341, -9.093407, -5.302198, -7.445055, -4.917582, 3.269231, -3.269231, 5.412088, 2.664835, 1.181319, 0.357143, -2.225275, 2.28022, -2.664835, 0.686813, -0.027473, -0.467033, -8.873626, -2.39011, 3.983516, 2.335165, -3.928571, -4.038462, 2.06044, -2.884615, 3.269231, 1.950549, -6.510989, -7.39011, -1.346154, 4.807692, -4.478022, -1.181319, -8.104396, 5.741758, -3.214286, -0.686813, 1.016484, 0.247253, -3.434066, 2.5, -5.796703, -2.994505, 0.192308, -4.532967, 1.785714, -1.291209, -0.686813, 3.104396, 0.906593, -6.565934, -6.565934], dtype=np.float32)
    y = np.array([-7.058824, -2.072829, -6.890756, 2.352941, 3.02521, -2.969188, -2.128852, -2.577031, 3.865546, 0.168067, -5.434174, 4.87395, -7.563025, -8.347339, 0.336134, -2.184874, 2.352941, -3.193277, -8.459384, -3.361345, 1.120448, -4.761905, -8.067227, -2.296919, 2.80112, -6.666667, 6.498599, -5.154062, -8.907563, -5.378151, -8.907563, -4.64986, 6.946779, -5.154062, -1.904762, -6.330532, -8.907563, -2.633053, 3.865546, -3.809524, 4.817927, -3.361345, 2.689076, 2.857143, -6.27451, -8.067227, -4.257703, -6.610644, 6.946779, -8.851541, -5.714286, 1.120448, 5.658263, -9.019608, -0.784314, -4.985994, -7.226891, 1.792717, -2.80112, -2.016807, 4.201681, -0.616246, 2.464986, -1.736695, 1.064426, -2.857143, -5.042017, -8.907563, -4.42577, -1.344538, -3.081232, 0.056022, 1.288515, -1.792717, -1.120448, 3.361345, 2.80112, 1.792717, -3.2493, -9.355742, 3.473389, -5.994398, -0.280112, -2.745098, -8.123249, -6.442577, -8.011204, 0.728291, 1.008403, -4.201681, 0.784314, -4.089636, 7.002801, -6.442577, -8.627451, 3.193277, -3.697479, -7.507003, -5.658263, -6.946779, 3.305322, -2.577031, -7.787115, -7.170868, 4.705882, 1.40056, -4.87395, 5.994398, 5.826331, -0.784314, 7.619048, 5.882353, -9.355742, -7.787115, 3.697479, -0.112045, -0.392157, 3.865546, -6.27451, -0.784314, -3.865546, 1.512605, 1.680672, -4.761905, -1.176471, -0.336134, -0.336134, 8.571429, -2.128852, -2.913165, -3.2493, -3.641457, 5.882353, -7.170868, 2.745098, 1.232493, -5.098039, -8.683473, -4.257703, 0.448179, -7.394958, -5.490196, 1.456583, 1.288515, -0.728291, -8.907563, -3.473389, -8.963585, 8.123249, 4.369748, -5.826331, 4.089636, -8.907563, -3.977591, 3.137255, -1.176471, -6.666667, 1.792717, -1.456583, -8.683473, 3.921569, 2.857143, -3.081232, 5.714286, -2.072829, 1.736695, 0.22409, -3.305322, 2.464986, 8.067227, -7.226891, -7.563025, -1.40056, -7.114846, 3.417367, -1.40056, -3.193277, -6.162465, -1.904762, 0.448179, -7.170868, 0.672269, -8.571429, -5.770308, -7.619048, -5.434174, -3.193277, 6.330532, 6.498599, -8.347339, -9.07563, 4.089636, 4.761905, -6.442577, -6.722689, -2.352941, -1.736695, -5.770308, 7.058824, 2.296919, -7.282913, -1.456583, 5.602241, -9.355742, -4.87395, -0.504202, -4.64986, -4.64986], dtype=np.float32)
    outputs = [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]
    print(len(x))
    print(len(y))
    print(len(outputs))
    for i in range(len(outputs)):
        if outputs[i]==0:
            outputs[i] = -1
    print(outputs) 


    iteration = 0
    while iteration <= MAX_ITERATION:
        global_error = 0
        for p in range(pattern_count):
            output = calculate_output(weights, x[p], y[p])

            local_error = outputs[p] - output
            weights[0] += LEARNING_RATE * local_error * x[p]
            weights[1] += LEARNING_RATE * local_error * y[p]
            weights[2] += LEARNING_RATE * local_error

            global_error += (local_error * local_error)

            # Simulating writing to MMRs (this part is hardware specific and won't work in Python)
            # For demonstration, we will just print the values instead
            print(f"Iteration: {iteration}, Subloop: {p}, Weights: {weights[0]}")
        print(f"Iteration: {iteration}, Subloop: {p}, Weights: {weights[0]}")
        iteration += 1
        # Simulating status update
        print("Running status")

    # Update status to indicate the completion of the training loop
    print("Finished status")

if __name__ == "__main__":
    main()
